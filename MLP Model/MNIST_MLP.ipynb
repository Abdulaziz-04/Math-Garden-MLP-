{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_MLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEmOtGwHB67p",
        "outputId": "4a9ba8d2-fd39-460c-b49e-2c9d69902bf3"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "import tensorflow as tf2\r\n",
        "import os\r\n",
        "from numpy.random import seed\r\n",
        "from time import strftime\r\n",
        "from PIL import Image\r\n",
        "seed(888)\r\n",
        "tf2.random.set_seed(404)\r\n",
        "%load_ext tensorboard\r\n",
        "!pip list | grep tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'grep' is not recognized as an internal or external command,\noperable program or batch file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsgU-DYUEmmF"
      },
      "source": [
        "#Constants\r\n",
        "X_TRAIN_PATH='./mnist/digit_xtrain.csv'\r\n",
        "Y_TRAIN_PATH='./mnist/digit_ytrain.csv'\r\n",
        "X_TEST_PATH='./mnist/digit_xtest.csv'\r\n",
        "Y_TEST_PATH='./mnist/digit_ytest.csv'\r\n",
        "TEST_IMG='./mnist/test_img.png'\r\n",
        "LABEL_COUNT=10 #Number of digits i.e. 0-9\r\n",
        "VALIDATION_SIZE=10000\r\n",
        "IMG_WIDTH=28\r\n",
        "IMG_HEIGHT=28\r\n",
        "CHANNEL=1\r\n",
        "TOTAL_INPUTS=784\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxfbP5fYEm7W",
        "outputId": "aa0d8dfb-cf42-4a05-bb04-d0e138fcca33"
      },
      "source": [
        "#Retreive the data\r\n",
        "xtrain=np.loadtxt(X_TRAIN_PATH,delimiter=',',dtype=int)\r\n",
        "ytrain=np.loadtxt(Y_TRAIN_PATH,delimiter=',',dtype=int)\r\n",
        "xtest=np.loadtxt(X_TEST_PATH,delimiter=',',dtype=int)\r\n",
        "ytest=np.loadtxt(Y_TEST_PATH,delimiter=',',dtype=int)\r\n",
        "print(xtrain.shape,ytrain.shape,xtest.shape,ytest.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (60000,) (10000, 784) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijqoSPKnEnIu",
        "outputId": "6dad9366-4f97-4909-f44a-7376dadbf1de"
      },
      "source": [
        "#Data Preprocessing \r\n",
        "#converting the range between 0 and 1\r\n",
        "xtrain,xtest=xtrain/255.0,xtest/255.0\r\n",
        "#Creating a sparse matrix where the y value represent 1 on a single row of 10 labels\r\n",
        "ytrain=np.eye(LABEL_COUNT)[ytrain]\r\n",
        "ytest=np.eye(LABEL_COUNT)[ytest]\r\n",
        "ytest.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Irk-jmEnWm",
        "outputId": "64c08acc-814b-45c9-8ad8-bf447c92ffdf"
      },
      "source": [
        "#Creating Validation and Training Datasets\r\n",
        "xval=xtrain[:VALIDATION_SIZE]\r\n",
        "yval=ytrain[:VALIDATION_SIZE]\r\n",
        "xtrain=xtrain[VALIDATION_SIZE:]\r\n",
        "ytrain=ytrain[VALIDATION_SIZE:]\r\n",
        "print(xtrain.shape,xval.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784) (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V98l8XIREnle"
      },
      "source": [
        "#Setting up Tensroflow graph\n",
        "tf.disable_v2_behavior()\n",
        "x=tf.placeholder(tf.float32,shape=[None,TOTAL_INPUTS],name='input-attr')\n",
        "y=tf.placeholder(tf.float32,shape=[None,LABEL_COUNT])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A45K22OEn0W"
      },
      "source": [
        "#Setting up the hyperparamters\r\n",
        "epoch_count=20 #5 -> 50 -> 20\r\n",
        "learning_rate=1e-3 # 1e-4 -> 1e-3\r\n",
        "layer_1=512\r\n",
        "layer_2=64\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7qv62btsjsy"
      },
      "source": [
        "#Note : These layers can be moulded into a single function as well\r\n",
        "with tf.name_scope('layer1'):\r\n",
        "  #Setting up the layers  \r\n",
        "  #LAYER #1\r\n",
        "  #Setting the weights of each layer\r\n",
        "  initial_w1=tf.truncated_normal(shape=[TOTAL_INPUTS,layer_1],stddev=0.1,seed=42)\r\n",
        "  w1=tf.Variable(initial_value=initial_w1)\r\n",
        "  #Setting the bias value\r\n",
        "  initial_b1=tf.constant(value=0.0,shape=[layer_1])\r\n",
        "  b1=tf.Variable(initial_value=initial_b1)\r\n",
        "  #Can also use tf.summary.histogram to keep track of w and b for each layer\r\n",
        "  #Constructing the first layer where it is the product of the placeholder and the input weights of the first layer\r\n",
        "  layer_1_in=tf.matmul(x,w1)+b1\r\n",
        "  #Treating the layer 1 result as activation function for the next layer\r\n",
        "  layer_1_out=tf.nn.relu(layer_1_in)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d9QhxDvsiHa"
      },
      "source": [
        "with tf.name_scope('layer2'):\r\n",
        "  #LAYER #2\r\n",
        "  #Setting up the weights\r\n",
        "  initial_w2=tf.truncated_normal(shape=[layer_1,layer_2],stddev=0.1,seed=42)\r\n",
        "  w2=tf.Variable(initial_value=initial_w2)\r\n",
        "  #Setting up the bias\r\n",
        "  initial_b2=tf.constant(value=0.0,shape=[layer_2])\r\n",
        "  b2=tf.Variable(initial_value=initial_b2)\r\n",
        "  #Constructing the second layer\r\n",
        "  layer_2_in=tf.matmul(layer_1_out,w2)+b2\r\n",
        "  #Building the activation function\r\n",
        "  layer_2_out=tf.nn.relu(layer_2_in)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVBIk_uTso-4"
      },
      "source": [
        "with tf.name_scope('output'):\r\n",
        "  #OUTPUT LAYER\r\n",
        "  #Setting up weights\r\n",
        "  #Final output will result into 10 labels\r\n",
        "  initial_w3=tf.truncated_normal(shape=[layer_2,LABEL_COUNT])\r\n",
        "  w3=tf.Variable(initial_value=initial_w3)\r\n",
        "  #Setting up the bias\r\n",
        "  initial_b3=tf.constant(value=0.0,shape=[LABEL_COUNT])\r\n",
        "  b3=tf.Variable(initial_value=initial_b3)\r\n",
        "  #Constructing the layer\r\n",
        "  layer_3_in=tf.matmul(layer_2_out,w3)+b3\r\n",
        "  #Building the activation function\r\n",
        "  layer_3_out=tf.nn.softmax(layer_3_in)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkncPpFTspSQ"
      },
      "source": [
        "#Loss Optimisation\r\n",
        "#For performing batch operations,loss mean value is required \r\n",
        "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=layer_3_out))\r\n",
        "#Setting up the optimizer\r\n",
        "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\r\n",
        "#Minimizing the loss function\r\n",
        "train_step=optimizer.minimize(loss)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlmoCDBYv2Nk"
      },
      "source": [
        "#Accuracy Metric\n",
        "#Pick up the max probability index from last layer and compare with Y i.e. the original placeholder\n",
        "with tf.name_scope('accuracy_calc'):\n",
        "  model_output=tf.argmax(layer_3_out,axis=1,name='output-attr')\n",
        "  correct_predictions=tf.equal(model_output,tf.argmax(y,axis=1))\n",
        "  #casting to float to obtain mean value from all batches to be executed\n",
        "  accuracy=tf.reduce_mean(tf.cast(correct_predictions,tf.float32))\n",
        "with tf.name_scope('performance'):\n",
        "  #Setting up the accuracy metric in summary\n",
        "  tf.summary.scalar('accuracy',accuracy)\n",
        "  tf.summary.scalar('loss',loss)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTdzKkq3JCF_",
        "outputId": "36f01a81-7a7a-49a7-9cd0-e27727efee71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Check input images in tensorboard\r\n",
        "img=tf.reshape(x,[-1,28,28,1])\r\n",
        "tf.summary.image('image_input',img,max_outputs=4)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'image_input:0' shape=() dtype=string>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WV_1f--UgxR"
      },
      "source": [
        "#Setting up folders for tensorboard event files \r\n",
        "folder_name=f'Model 1 at {strftime(\"%H %M\")}'\r\n",
        "dir_name=os.path.join('logs',folder_name)\r\n",
        "try:\r\n",
        "  os.makedirs(dir_name)\r\n",
        "except OSError as err:\r\n",
        "  print(err)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvGgnEvN9TkW",
        "outputId": "012e2b73-0938-4b58-ecdb-ce224b70e07f"
      },
      "source": [
        "#Run Session\r\n",
        "session=tf.Session()\r\n",
        "\r\n",
        "#Creating Summaries\r\n",
        "merged_summary=tf.summary.merge_all()\r\n",
        "#Creates a subfilder\r\n",
        "train_writer=tf.summary.FileWriter(dir_name+'/train')\r\n",
        "#Creates a session graph\r\n",
        "train_writer.add_graph(session.graph)\r\n",
        "#For Validation session\r\n",
        "validation_writer=tf.summary.FileWriter(dir_name+'/validation')\r\n",
        "\r\n",
        "#Initializing all variables\r\n",
        "init=tf.global_variables_initializer()\r\n",
        "session.run(init)\r\n",
        "#To check initialized values\r\n",
        "b3.eval(session)\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCVaxCspv2ia",
        "outputId": "69545097-c664-4573-b861-371cf1cf442d"
      },
      "source": [
        "#Creating Batches here we have 50k samples so we divide them into group of 1000s\r\n",
        "batch_size=1000\r\n",
        "num_examples=ytrain.shape[0]\r\n",
        "iterations=int(num_examples/batch_size)\r\n",
        "idx=0\r\n",
        "iterations"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S_uQJNW_mVV"
      },
      "source": [
        "def next_batch(batch_size,data,labels):\r\n",
        "  global num_examples,idx\r\n",
        "  start=idx\r\n",
        "  idx+=batch_size\r\n",
        "  end=idx\r\n",
        "  if(idx>num_examples):\r\n",
        "    start=0\r\n",
        "    idx=batch_size\r\n",
        "  return data[start:end],labels[start:end]\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kv7RyE8d_muE",
        "outputId": "114d315d-a299-4d97-966f-2cea5964cefe"
      },
      "source": [
        "#Training Loop\n",
        "#Number of passes for the whole dataset\n",
        "for epoch in range(epoch_count):\n",
        "  #Passing through each batch in dataset\n",
        "  #####TRAINING DATASET #####\n",
        "  for itr in range(iterations):\n",
        "    batchx,batchy=next_batch(batch_size=batch_size,data=xtrain,labels=ytrain)\n",
        "    feed_dictionary={x:batchx,y:batchy}\n",
        "    #Running the session based on the data values\n",
        "    session.run(train_step,feed_dict=feed_dictionary)\n",
        "    #Summary for tensorboard and accuracy to directly print out \n",
        "  graph_summary_train,batch_accuracy=session.run(fetches=[merged_summary,accuracy],feed_dict=feed_dictionary)\n",
        "  train_writer.add_summary(graph_summary_train,epoch)\n",
        "  print(f'Epoch No. : {epoch} \\t Accuracy is : {batch_accuracy}')\n",
        "  ####VALIDATION DATASET ####\n",
        "  graph_summary_val=session.run(fetches=merged_summary,feed_dict={x:xval,y:yval})\n",
        "  validation_writer.add_summary(graph_summary_val,epoch)\n",
        "\n",
        "print(\"Training Completed\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epcoh No. : 0 \t Accuracy is : 0.7689999938011169\n",
            "Epcoh No. : 1 \t Accuracy is : 0.8709999918937683\n",
            "Epcoh No. : 2 \t Accuracy is : 0.8849999904632568\n",
            "Epcoh No. : 3 \t Accuracy is : 0.972000002861023\n",
            "Epcoh No. : 4 \t Accuracy is : 0.9810000061988831\n",
            "Epcoh No. : 5 \t Accuracy is : 0.984000027179718\n",
            "Epcoh No. : 6 \t Accuracy is : 0.9860000014305115\n",
            "Epcoh No. : 7 \t Accuracy is : 0.984000027179718\n",
            "Epcoh No. : 8 \t Accuracy is : 0.9850000143051147\n",
            "Epcoh No. : 9 \t Accuracy is : 0.9909999966621399\n",
            "Epcoh No. : 10 \t Accuracy is : 0.9900000095367432\n",
            "Epcoh No. : 11 \t Accuracy is : 0.9879999756813049\n",
            "Epcoh No. : 12 \t Accuracy is : 0.9919999837875366\n",
            "Epcoh No. : 13 \t Accuracy is : 0.9919999837875366\n",
            "Epcoh No. : 14 \t Accuracy is : 0.9909999966621399\n",
            "Epcoh No. : 15 \t Accuracy is : 0.9919999837875366\n",
            "Epcoh No. : 16 \t Accuracy is : 0.9900000095367432\n",
            "Epcoh No. : 17 \t Accuracy is : 0.9919999837875366\n",
            "Epcoh No. : 18 \t Accuracy is : 0.9919999837875366\n",
            "Epcoh No. : 19 \t Accuracy is : 0.9919999837875366\n",
            "Training Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-21-2a1a832676bc>:4: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
            "WARNING:tensorflow:From C:\\Users\\abdul\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:200: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: Saved MLP Model\\saved_model.pb\n"
          ]
        }
      ],
      "source": [
        "#Saving attributes required to save the model\n",
        "output_attr={'accuracy_calc/output-attr':model_output}\n",
        "input_attr={'input-attr':x}\n",
        "tf.saved_model.simple_save(session,'Saved MLP Model',input_attr,output_attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9BSw-zSO_KN",
        "outputId": "bc3609df-3d06-4602-cdad-454e7cb3a06d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Making Predictions\r\n",
        "img=Image.open(TEST_IMG)\r\n",
        "#convert this image to grayscale\r\n",
        "img_gs=img.convert('L')\r\n",
        "img_inv_gs=np.invert(img_gs) #Invert colors as input is black on white\r\n",
        "final_img=img_inv_gs.ravel()\r\n",
        "final_img.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5xIdKfKO_qy",
        "outputId": "e510cab0-232c-4a42-c533-0d4247e0d462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#sample prediction\r\n",
        "prediction=session.run(fetches=tf.argmax(layer_3_out,axis=1),feed_dict={x:[final_img]})\r\n",
        "print(prediction)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zmiAxUjSTyp",
        "outputId": "6785fcf5-5e36-41aa-cb25-8dbe75fc9c17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Using the model on test dataset\r\n",
        "test_acc=session.run(fetches=accuracy,feed_dict={x:xtest,y:ytest})\r\n",
        "print(f'Test Accuracy : {test_acc:0.2%}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy : 97.09%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxcwyi69T9Xx"
      },
      "source": [
        "#Resetting all calculations\r\n",
        "train_writer.close()\r\n",
        "validation_writer.close()\r\n",
        "session.close()\r\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}